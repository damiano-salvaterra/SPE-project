{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e22bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "# =============================================================================\n",
    "# --- Configuration ---\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "# 1. Set this to the parent directory containing your topology folders\n",
    "#    (e.g., the 'poisson_traffic' folder that holds 'random_20nodes')\n",
    "PATH_TO_RESULTS_PARENT_FOLDER = Path(\"/home/damole/Documents/develop/SPE-project/results/batch_2025-11-12_10-54-41/poisson_traffic\")\n",
    "\n",
    "# 2. Set this to the specific topology folder you want to analyze\n",
    "#    (e.g., \"random_20nodes\" or \"cluster-tree_20nodes\")\n",
    "TOPOLOGY_FOLDER_TO_ANALYZE = \"random_20nodes\"\n",
    "\n",
    "# --- End of Configuration ---\n",
    "\n",
    "\n",
    "# Log file names (as defined in run_simulation.py and monitors)\n",
    "PDR_LOG_FILE = \"log_PDR.csv\"\n",
    "LATENCY_LOG_FILE = \"log_e2eLat.csv\"\n",
    "\n",
    "# Set plot style for better aesthetics\n",
    "sns.set(style=\"whitegrid\", palette=\"muted\")\n",
    "# Suppress warnings from seaborn when data is missing for KDE\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='seaborn')\n",
    "\n",
    "# =============================================================================\n",
    "# --- Helper Functions ---\n",
    "# =============================================================================\n",
    "\n",
    "def process_pdr_file(file_path):\n",
    "    \"\"\"\n",
    "    Reads a single PDR log file from one run (seed).\n",
    "    Calculates the PDR for that run (which is the mean of the 'delivered' column).\n",
    "    Returns the PDR value (float) or None if the file is invalid.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the CSV. We use skipinitialspace to handle\n",
    "        # the potential leading space in the header row.\n",
    "        df_pdr = pd.read_csv(file_path, skipinitialspace=True)\n",
    "        \n",
    "        if df_pdr.empty:\n",
    "            print(f\"  - WARNING: PDR file is empty, skipping: {file_path}\", file=sys.stderr)\n",
    "            return None\n",
    "        \n",
    "        #\n",
    "        # The 'delivered' column is 0 or 1. The mean of this column\n",
    "        # is the Packet Delivery Rate for this simulation run.\n",
    "        if 'delivered' not in df_pdr.columns:\n",
    "            print(f\"  - ERROR: 'delivered' column not found in: {file_path}\", file=sys.stderr)\n",
    "            return None\n",
    "            \n",
    "        run_pdr = df_pdr['delivered'].mean()\n",
    "        return run_pdr\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        # This is not an error, it just means the simulation run failed to\n",
    "        # produce this file. We will report it and skip it.\n",
    "        print(f\"  - WARNING: PDR file not found, skipping: {file_path}\", file=sys.stderr)\n",
    "        return None\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"  - WARNING: PDR file is empty (EmptyDataError), skipping: {file_path}\", file=sys.stderr)\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"  - ERROR processing PDR file {file_path}: {e}\", file=sys.stderr)\n",
    "        return None\n",
    "\n",
    "def process_latency_file(file_path):\n",
    "    \"\"\"\n",
    "    Reads a single E2E Latency log file from one run (seed).\n",
    "    Returns a list of all individual packet latencies from that run.\n",
    "    Returns an empty list if the file is invalid or no packets were delivered.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        #\n",
    "        # The 'latency' column contains the E2E latency for each received packet.\n",
    "        df_lat = pd.read_csv(file_path, skipinitialspace=True)\n",
    "        \n",
    "        if df_lat.empty:\n",
    "            # This is not an error; it just means PDR was 0.\n",
    "            return []\n",
    "        \n",
    "        if 'latency' not in df_lat.columns:\n",
    "            print(f\"  - ERROR: 'latency' column not found in: {file_path}\", file=sys.stderr)\n",
    "            return []\n",
    "            \n",
    "        # Return all latencies from this run\n",
    "        return df_lat['latency'].tolist()\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        # This is expected if PDR was 0 for the run.\n",
    "        return [] \n",
    "    except pd.errors.EmptyDataError:\n",
    "        # This is also expected if PDR was 0.\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"  - ERROR processing Latency file {file_path}: {e}\", file=sys.stderr)\n",
    "        return []\n",
    "\n",
    "# =============================================================================\n",
    "# --- Main Analysis Script ---\n",
    "# =============================================================================\n",
    "\n",
    "# Construct the full path to the specific topology folder we want to analyze\n",
    "analysis_base_path = PATH_TO_RESULTS_PARENT_FOLDER / TOPOLOGY_FOLDER_TO_ANALYZE\n",
    "\n",
    "if not analysis_base_path.is_dir():\n",
    "    print(f\"ERROR: Analysis directory not found at: {analysis_base_path}\", file=sys.stderr)\n",
    "    print(\"Please check your 'PATH_TO_RESULTS_PARENT_FOLDER' and 'TOPOLOGY_FOLDER_TO_ANALYZE' variables.\", file=sys.stderr)\n",
    "else:\n",
    "    print(f\"Starting analysis for topology: {TOPOLOGY_FOLDER_TO_ANALYZE}\\n\")\n",
    "    \n",
    "    # Find channel folders (e.g., 'stable', 'lossy', 'unstable')\n",
    "    channel_dirs = sorted([d for d in analysis_base_path.iterdir() if d.is_dir()])\n",
    "    \n",
    "    if not channel_dirs:\n",
    "        print(f\"  No channel folders (e.g., 'stable', 'lossy') found in {analysis_base_path}\", file=sys.stderr)\n",
    "\n",
    "    # --- Iterate over each Channel Configuration ---\n",
    "    for channel_dir in channel_dirs:\n",
    "        config_name = f\"{TOPOLOGY_FOLDER_TO_ANALYZE} / {channel_dir.name}\"\n",
    "        print(\"=\"*70)\n",
    "        print(f\"Processing Configuration: {config_name}\")\n",
    "        print(\"=\"*70)\n",
    "\n",
    "        # Find all replication runs (seed folders) for this configuration\n",
    "        seed_dirs = sorted([d for d in channel_dir.iterdir() if d.is_dir()])\n",
    "        \n",
    "        if not seed_dirs:\n",
    "            print(f\"  No simulation runs (seed folders) found in {channel_dir}.\\n\")\n",
    "            continue\n",
    "\n",
    "        # These lists will store the metrics\n",
    "        all_run_pdrs = []\n",
    "        all_packet_latencies = []\n",
    "        \n",
    "        print(f\"  Found {len(seed_dirs)} simulation runs (seeds). Processing...\")\n",
    "        valid_pdr_runs = 0\n",
    "        valid_latency_runs = 0\n",
    "\n",
    "        # --- Iterate over each Run (Seed) ---\n",
    "        for seed_dir in seed_dirs:\n",
    "            # --- PDR Processing ---\n",
    "            pdr_file = seed_dir / PDR_LOG_FILE\n",
    "            run_pdr = process_pdr_file(pdr_file)\n",
    "            if run_pdr is not None:\n",
    "                all_run_pdrs.append(run_pdr)\n",
    "                valid_pdr_runs += 1\n",
    "\n",
    "            # --- Latency Processing ---\n",
    "            latency_file = seed_dir / LATENCY_LOG_FILE\n",
    "            run_latencies = process_latency_file(latency_file)\n",
    "            if run_latencies:\n",
    "                all_packet_latencies.extend(run_latencies)\n",
    "                valid_latency_runs += 1\n",
    "        \n",
    "        print(f\"  Processed {len(seed_dirs)} runs: Found {valid_pdr_runs} valid PDR logs and {valid_latency_runs} valid Latency logs.\")\n",
    "\n",
    "\n",
    "        # --- Analyze and Plot PDR ---\n",
    "        if not all_run_pdrs:\n",
    "            print(\"\\n  No valid PDR data found for this configuration.\")\n",
    "        else:\n",
    "            pdr_array = np.array(all_run_pdrs)\n",
    "            mean_pdr = np.mean(pdr_array)\n",
    "            std_pdr = np.std(pdr_array)\n",
    "            \n",
    "            print(\"\\n--- PDR Results ---\")\n",
    "            print(f\"  Mean PDR (averaged over runs): {mean_pdr:.4f}\")\n",
    "            print(f\"  Std. Dev. of PDR (run-to-run): {std_pdr:.4f}\")\n",
    "            print(f\"  (Based on {len(pdr_array)} simulation runs)\")\n",
    "\n",
    "            # Plot PDR Distribution\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            ax_pdr = sns.histplot(pdr_array, kde=True, bins=max(10, len(pdr_array)//5), stat=\"density\", alpha=0.6)\n",
    "            ax_pdr.axvline(mean_pdr, color='red', linestyle='--', \n",
    "                           label=f'Mean PDR: {mean_pdr:.4f}')\n",
    "            \n",
    "            ax_pdr.set_title(f'PDR Distribution for {config_name}\\n(Distribution of {len(pdr_array)} Run-Averages)')\n",
    "            ax_pdr.set_xlabel('Packet Delivery Rate (PDR) per Run')\n",
    "            ax_pdr.set_ylabel('Density')\n",
    "            ax_pdr.legend()\n",
    "            plt.show() # Display the plot in Jupyter\n",
    "\n",
    "        # --- Analyze and Plot Latency ---\n",
    "        if not all_packet_latencies:\n",
    "            print(\"\\n  No Latency data found for this configuration (no packets were delivered).\")\n",
    "        else:\n",
    "            latency_array = np.array(all_packet_latencies)\n",
    "            mean_latency = np.mean(latency_array)\n",
    "            std_latency = np.std(latency_array)\n",
    "            \n",
    "            print(\"\\n--- E2E Latency Results ---\")\n",
    "            print(f\"  Mean Latency (averaged over all packets): {mean_latency:.4f} s\")\n",
    "            print(f\"  Std. Dev. of Latency (all packets): {std_latency:.4f} s\")\n",
    "            print(f\"  (Based on {len(latency_array)} total packets delivered across all runs)\")\n",
    "\n",
    "            # Plot Latency Distribution\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            \n",
    "            # Check for wide variance to decide on log scale\n",
    "            min_lat = np.min(latency_array)\n",
    "            max_lat = np.max(latency_array)\n",
    "            # Add epsilon (1e-9) to avoid division by zero if min_lat is 0\n",
    "            #use_log_scale = (max_lat / (min_lat + 1e-9)) > 100\n",
    "            use_log_scale = False\n",
    "\n",
    "            # *** FIX IS HERE ***\n",
    "            # 1. Create the plot and get the axes object\n",
    "            ax_lat = sns.histplot(latency_array, kde=True, bins=50, alpha=0.6,\n",
    "                                  color='blue' if not use_log_scale else 'purple')\n",
    "            \n",
    "            # 2. Add the vertical line\n",
    "            ax_lat.axvline(mean_latency, color='red', linestyle='--', \n",
    "                           label=f'Mean Latency: {mean_latency:.4f} s')\n",
    "            \n",
    "            title = f'E2E Latency Distribution for {config_name}\\n({len(latency_array)} total packets delivered)'\n",
    "            xlabel = 'E2E Latency (s)'\n",
    "            \n",
    "            # 3. Apply log scale using matplotlib directly, which avoids the error\n",
    "            if use_log_scale:\n",
    "                ax_lat.set_xscale('log')\n",
    "                xlabel += ' [Scale]'\n",
    "                \n",
    "            ax_lat.set_title(title)\n",
    "            ax_lat.set_xlabel(xlabel)\n",
    "            ax_lat.set_ylabel('Density')\n",
    "            ax_lat.legend()\n",
    "            plt.show() # Display the plot in Jupyter\n",
    "            \n",
    "        print(\"\\n\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"Analysis complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
